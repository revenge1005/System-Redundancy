## 목차

2-1. [리버스 프록시 도입](#2-1-리버스-프록시-도입)

2-2. [웹 서버의 다중화 - DNS 라운드로빈]()

<br>

---

<br>

# 2-1. 리버스 프록시 도입
> IPVS(LVS)와 같은 로드밸런서는 L4 레벨에서 패킷을 전송하기만 할 뿐, 웹 서버가 클라이언트으로부터의 요청에 직접 응답하는 구성이라는 점은 변함이 없다. 여기서 로드밸런서 대신 리버스 프록시(Reverse Proxy) 서버를 넣음으로써 보다 유연하게 부하를 분산할 수 있게 된다.

> 리버스 프록시는 클라이언트로부터의 요청을 받아서 웹 서버로 요청을 전송하면, 웹 서버는 요청을 받아서 처리를 하지만 응답은 클라이언트로 보내지 않고 리버스 프록시로 반환한다. 요청을 받은 리버스 프록시는 그 응답을 클라이언트로 반환한다.

<br>

## ⓐ 프록시(Proxy) 서버
> 프록시 서버란 클라이언트가 자신을 거쳐 다른 네트워크에 접속할 수 있도록 중간에서 대신 전달해주는 서버

<br>

#### 【 Forward Proxy 】
> 클라이언트에서 요청을 할 때 직접 요청하는 것이 아닌 프록시 서버를 거치는 방식

+ **보안**

    - [x] 클라이언트는 Forward Proxy를 통해서만 외부에 요청을 하기 때문에 클라이언트가 해당 서버에 직접적으로 접근하는 것을 방지할 수 있다. (Ex. 클라이언트가 특정 사이트에 접근할 수 없도록 막을 수 있는 기능)<br><br>

+ **캐싱**

    - [x] 클라이언트가 요청을 할 경우, Forward Proxy는 해당 요청을 캐싱하여 동일한 요청이 들어올 경우 캐싱된 데이터를 전달함 (캐싱된 데이터를 받아오기 때문에 서버에 부하를 줄일 수 있음) <br><br>

+ **암호화**

    - [x] 클라이언트의 요청은 Forward Proxy를 통과할 때 암호화 됨 <br><br>
    - [x] 암호화 된 요청은 다른 서버를 통과할 떄 필요한 최소한의 정보만 갖게 되는데, 이는 클라이언트의 IP를 숨길 수 있다는 장점이 있다. (요청을 받은 서버에서 IP를 역 추적해도 프록시 서버의 IP만 알 수 있게 됨) 

<br>

#### 【 Reverse Proxy 】
> 서버에서 클라이언트로 직접 데이터를 전달하지 않고 프록시 서버를 거치는 방식

+ **로드밸런싱**

    - [x] 여러 대의 서버에 트래픽을 분산시켜 서비스의 퍼포먼스와 신뢰성을 향상하기 위한 서비스 <br><br>

+ **보안**   

    - [x] 서버의 IP를 노축시키지 않을 수 있기 때문에 서버에 대한 1차적인 공격을 막을 수 있다. <br><br>

+ **캐싱**

    - [x] 프록시 서버에 캐싱되어 있는 데이터를 사용하여 클라이언트에 대한 요청을 처리 <br><br>

+ **SSL Offloading(or Termination)**
    - [x] 프록시 서버가 SSL을 전담해서 처리하고 서버에게 흘려보내는 기능 <br><br>
    - [x] SSL 암호화는 서버와 클라이언트 간에 데이터를 주고 받을 때 암호화 하는 것으로 해당 기능은 프록시 서버가 SSL 암호화를 해제하고 서버에는 암호화가 해제된 데이터를 전달하는 것이다. <br><br>
    - [x] SSL Passthrough - 특별한 액션 없이 그대로 흘려보내는 기능 <br><br>
+ **압축**
    - [x] 서버의 응답을 클라이언트로 반환하기 전에 압축하면 필요한 대여폭이 줄어들어 전송 속도 향상 

<br>

## ⓑ 리버스 프록시 구체적인 이점/기능

<br>

#### 【 HTTP 요청 내용에 떄란 시스템의 동작 제어 (L7 스위치가 하는 역할과 동일함) 】
> 리버스 프록시가 있으면 예를 들어 HTTP 요청 내에서 URL 보고 최종적인 처리를 각기 다른 서버에 분배하는 제어가 가능해진다.

<br>

#### 【 시스템 전체의 메모리 사용효율 향상 】
> 정적 컨텐츠만 반환하는 서버에 비해 동적 컨텐츠를 반환하는 서버에서는 수 배의 메모리를 소비하는 것도 드물지 않다. **서버는 클라이언트의 하나의 요청에 대해 하나의 프로세스/쓰레드를 할당해서 처리하는 방식을 취하고 있으며 정적 컨텐츠를 반환하는, 즉 파일에 쓰인 내용을 그대로 반환하기만 하면 될 경우도 동일한 방식으로 반환하게 된다.**

+ **동적으로 생성된 하나의 HTML 페이지 내에 이미지가 30개 정도 사용되고 있다고 가정할 때** <br><br>
    - [x] 이 페이지에 대한 요청은 첫 요청 한 번만 동적 컨텐츠를 요구하게 되고 첫 요청으로 HTML 동적으로 생성되며 이 HTML은 클라이언트인 브라우저에 의해 다운로드 된다. <br><br>
    - [x] 브라우저는 HTML을 해석해서 필요한 이미지 파일이나 스크립트 파일을 서버에 요청한다. <br><br>
    - [x] 결과적으로 동적 요청 (1회) + 정적 요청 (30회)가 된다. <br><br>
+ **모두 AP 서버에서 응답할 경우** <br><br>
    - [x] 모두 AP 서버에서 응답할 경우, 단 1회 동적 요청을 처리할 뿐임에도 나머지 30회의 정적인 요청에 대해 응답할 때에도 대량의 메모리를 소비하게 된다. <br><br>
    - [x] 이는 이미지든 동적 컨텐츠든 똑같이 하나의 요청에 대해 하나의 프로세스/쓰레드로 응답할 필요가 있기 때문이다. <br><br>
+ **서버를 분할할 경우** <br><br>
    - [x] 정적 컨텐츠는 메모리 소비량이 적은 웹 서버가 응답하고, 동적 컨텐츠만 애플레킹션으로 응답하는 형태의 구성이 가능해진다. <br><br>
    - [x] 리버스 프록시를 통해 정적 컨텐츠, 동적 컨텐츠에 대한 요청을 각각의 서버로 할당할 수 있다 (ex. URL의 내용을 보고 요청을 할당할 곳을 변경한다.) <br><br>
    - [x] 이때, 리버스 프록시 자신도 웹 서버라는 특징을 살려서 (정적 컨텐츠를 반환하기 위해 웹 서버를 별도로 준비하는 것이 아니라) 정적 컨탠츠는 리버스 프록시 자신이 반환하는 형태의 구성이 일반적이다.

<br>

#### 【 웹 서버가 응답하는 데이터의 버퍼링의 역할 】
+ **HTTP의 Keep-Alive** <br><br>
    - [x] 특정 클라이언트가 한 번에 다수의 컨텐츠를 동일한 웹 서버로부터 얻고자 할 경우, 다수의 HTTP 요청마다 서버와 접속하고 끊고를 반복하는 것은 비효율적이다. <br><br>
    - [x] 최초 요청 시 연결된 서버와의 접속을 해당 요청이 종료한 후에도 접속을 끊지 않고 유지한 채로 이어지는 요청에 해당 접속을 계속 사용함으로써, 하나의 접속으로 다수의 요청을 처리할 수 있도록 실현한 것이 Keep-Alive이다. <br><br>
    - [x] Kepp-Alive는 한번 연결된 접속을 당분간 유지하는 특성상, 웹 서버에 부하를 야기한다 <br><br>
    - [x]  구체적으로는 특정 클라이언틀부터 요청을 받은 프로세스/쓰레드는 그 시점으로부터 일정 시간 동안 해당 클라이언트로의 응답을 위해서 점유되는 것을 들 수 있다. <br><br>
+ **메모리 소비와 Keep-Alive ON/OFF** <br><br>
    - [x] 하나의 프로세스당 메모리 소비량이 많은 AP 서버에서는 하나의 호스트 내에 실행될 수 있는 최대 프로세스 수는 50 ~ 100개 정도다.  <br><br>
    - [x] 이때 리버스 프록시 없이 Keep-Alive를 설정한 경우 50~100개의 프로세스 중 다수가 Keep-Alive의 접속 유지를 위해 소비되고 Keep-Alive를 OFF로 설정하면 클라이언트에서 볼 때의 체감속도가 저하된다. <br><br>
    - [x] 리버스 프록시 도입한 경우를 생각해 보면, 일반적으로 리버스 프록시 역할을 하는 웹 서버는 프로세스당 메모리 소비량이 그다지 많지 않으므로 하나의 호스트 내에 1000~10000 프로세스를 실행할 수도 있다. <br><br>
    - [x] 이 경우에는 일부 프로세스가 Keep-Alive 연결을 유지하기 위해 소비된다고 해도 문제가 되지 않는다. <br><br>
    - [x] 그리고 클라이언트와 리버스 프록시 사이에만 "Keep-Alive ON"으로 하고, 리버스 프록시와 AP 서버 사이는 Keep-Alive OFF로 한다. <br><br>
    - [x] 이렇게 하면 AP 서버 측은 프로세스 수가 적더라도 하나의 요청이 종료되면 곧바로 그 후에 다른 요청에 응답할 수 있으며 전체적으로 동시에 다룰 수 있는 클라이언트의 수는 많아지고 또한 전송량도 향상된다. <br><br>
+ **아파치 모듈을 이용한 처리의 제어** <br><br>
    - [x] 리버스 프록시로 아파치를 선택한 경우, 해당 리버스 프록시에 아파치 모듈을 내장해서 HTTP 요청의 전/후처리로 임의의 프로그램을 실행 시킬 수가 있다.  <br><br>
        - mod_deflate : 컨텐츠를 gzip 압축하는 아파치 모듈, AP 서버로부터 수신한 HTTP 응답을 클라이언트에 압축해서 보낼 수가 있다. <br><br>
        - mod_ssl : AP 서버로부터의 응답을 SSL로 암호화할 수 있다. <br><br>
        - mod_dosdetector : DoS 공격 대책용 모듈 <br><br>
    - [x] 이외에도 lighttpd 등, 써드파티 제품 모듈/플러그인을 내장할 수 있는 웹 서버가 몇 종류 있으며, 이를 리버스 프록시로 이용하면 유사한 이점을 얻을 수 있다.

<br>

---

<br>

# 2-2. 캐시서버 도입
> 캐시서버는 인터넷 서비스 속도를 높이기 위해 사용자와 가까운 곳에 데이터를 임시 저장하여 빠르게 제공해주는 프록시 서버를 의미합니다. 

<br>

## ⓐ 캐시란
> 데이터에 빠르게 접근하기 위해 자주 사용되는 데이터나 값을 미리 복사해 놓는 임시 장소를 의미한다.

<br>

#### 【 캐시를 적용하기 좋은 데이터 】
> 서버에 데이터를 요청하면, 해당 서버가 응답을 반환할 때까지 페이지가 로드되지 않는다. 즉, 페이지 로딩에 필요한 정적 리소스를 캐싱하여 사용하게 되면, 요청을 보내는 네트워크 요청 횟수를 줄일 수 있을 뿐만 아니라 서버 응답을 기다려야 할 필요도 없기 때문에 사용자에게 보다 빠르게 화면을 보여줄 수 있다.

- [x] 자주 참조되는 데이터<br><br>
- [x] 자주 변경되지 않는 데이터<br><br>
- [x] 동일한 입력에 대해 동일한 출력을 보장하는 데이터 <br><br>

#### 【 캐시 종류 】

+ **Private Cache** <br><br>
    - [x] 웹 브라우저에 저장디는 캐시이며, 다른 사람이 접근할 수 없다. <br><br>
    - [x] 단, 서버 응답에 Autorization 헤더가 포함되어 있다면 Private Cache에 저장되지 않는다.<br><br>
+ **Shared Cache** <br><br>
    - [x] Shared Cache는 웹 브라우저와 서버 사이에서 동작하는 캐시를 의미하며, 2가지로 나뉜다.<br><br>
        + **Prxoy Cache :** 포워드 프록시에서 동작하는 캐시 <br><br>
        + **Managed Cache :** CDN 서비스 그리고 리버스 프록시에서 동작하는 캐시

<br>

#### 【 대표적인 오픈소스 캐시 솔루션 】

+ Memcached
+ Redis
+ Squid
+ Nginx / Apache Traffic Server
+ Varnish Cache

## ⓑ Squid 캐시서버
+ Squid는 HTTP, HTTPS, FTP 등에서 이용되는 오픈소스 캐시 프록시 서버

+ Squid는 HTTP 프로토콜의 캐시기능을 전제로 한 캐시서버로, 따라서 HTML, CSS, Javascript 등의 정적인 컨텐츠를 캐싱할 때 사용된다.

<br>

#### 【 Squid 설정 예시 】
> Squid를 리버스 프록시로 이용할 경우, 구성은 다양하지만 여기서는 아파치로 구축한 리버스 프록시와 벤엔드인 AP 서버 사이에 넣는 구성을 예를 들었다.
```
                    192.168.0.150
                <-  [ Squid-1 ]   <-   
 [ AP 서버 ] 	                    		[ Apache ] (mod_proxy_balancer나 LVS로 두 대의 Squid로의 분배를 수행)
192.168.0.100   <-  [ Squid-2 ]   <-	         
                    192.168.0.151
```
```
# Squid를 80번 포트에 바인드
http_port 80 	

# 원본 서버는 백엔드 서버
cache_peer 192.168.0.100 parent 80 no-query originserver	

# 형제(sibling) Squid는 192.168.0.151에 있고, 포트 3130으로 송수신함
cache_peer 192.168.0.151 sibling 80 3130                    

# 모든 서버에서 접근가능 (LAN 내부이므로 접근제어를 하지 않음)
http_access allow all						                
			
# 캐시 스토리지는 coss를 이용
cache_dir coss /var/squid/coss 8000 block-size=512 max-size=524288	

# 30분간 컨텐츠를 캐시 
refresh_pattern . 30 20% 3600                                       

# KeepAlive에 의한 접속유지를 무효화
client_persistent_connections off	
server_persistent_connections off

# 형제와의 캐시 존재확인시 타임아웃을 2000ms로 설정
icp_query_timeout 2000			      
```

## ⓒ memcached
+ 동적 컨텐츠의 처리 속도를 높이는데 사용되는 분산 메모리 캐시서버

+ 서버의 메모리(in-memory)에 저장하는 방식으로, 데이터 반환 속도가 빠르다는 장점으로 서버의 성능을 향상하는 것이 목적인 캐시에 최적화 되어 있다.

+ NoSQL 데이터베이스로 key-value 쌍으로 활용해서 데이터를 저장한다.